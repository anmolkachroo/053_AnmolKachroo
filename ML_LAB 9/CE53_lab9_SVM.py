# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11JmIM2PnvYjhz_fEPCakr_dc6dX2ccC_

#Aim: To implement SVM using scikit-learn library and train it to classify Breast Cancer Data.

##Key Terms: 

**Hyperplane:** A hyperplane is a decision plane which separates between a set of objects having different class memberships.

**Support Vectors :** Support vectors are the data points, which are closest to the hyperplane. These points will define the separating line better by calculating margins.

**Margin :** A margin is a gap between the two lines on the closest class points. This is calculated as the perpendicular distance from the line to support vectors or closest points. If the margin is larger in between the classes, then it is considered a good margin, a smaller margin is a bad margin.

**SVM Kernel :** The SVM algorithm is implemented in practice using a kernel. A kernel transforms an input data space into the required form.

**Linear Kernel :** A linear kernel can be used as normal dot product any two given observations. The product between two vectors is the sum of the multiplication of each pair of input values.

$ K(x, xi) = sum(x * xi) $

**Polynomial Kernel :** A polynomial kernel is a more generalized form of the linear kernel. The polynomial kernel can distinguish curved or nonlinear input space.
$ K(x,xi) = 1 + sum(x * xi)^d$

**RBF (Radial Basis Function) Kernel :** The Radial basis function kernel is a popular kernel function commonly used in support vector machine classification.RBF can map an input space in infinite dimensional space.
$ K(x,xi) = exp(-gamma * sum((x xi^2)) $

Here gamma is a parameter, which ranges from 0 to 1. A higher value of gamma will perfectly fit the training dataset, which causes over-fitting. Gamma=0.1 is considered to be a good default value. The value of gamma needs to be manually specified in the learning algorithm.

***Excercise***
"""

import matplotlib.pyplot as plt
from sklearn import svm
from sklearn.model_selection import train_test_split
import numpy as np
import seaborn as sb
import matplotlib.pyplot as plt

from sklearn import datasets
digits=datasets.load_digits()
#print the targets
print("Targets: ",digits.target_names)

# print data(feature)shape
digits.data.shape

#print targets
print(digits.target)

# Split dataset into training set and test set
X_train,X_test,Y_train,Y_test=train_test_split(digits.data,digits.target,test_size=0.2,random_state=53)

#Create a svm Classifier
clf_linear = svm.SVC(kernel='linear',random_state=53) # Linear Kernel
#Train the model using the training sets
clf_linear.fit(X_train,Y_train)
#Predict the response for test dataset
y_pred_linear = clf_linear.predict(X_test)

from sklearn import metrics
# Model Accuracy: how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(Y_test, y_pred_linear))
# Model Precision: what percentage of positive tuples are labeled as such?
print("Precision:",metrics.precision_score(Y_test, y_pred_linear,average='weighted'))
# Model Recall: what percentage of positive tuples are labelled as such?
print("Recall:",metrics.recall_score(Y_test, y_pred_linear,average='weighted'))

#using rbf kernel
clf_rbf = svm.SVC(kernel='rbf',gamma=0.005,random_state=53) # rbf Kernel
clf_rbf.fit(X_train,Y_train)
#Predict the response for test dataset
y_pred_rbf = clf_rbf.predict(X_test)

# Model Accuracy: how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(Y_test, y_pred_rbf))
# Model Precision: what percentage of positive tuples are labeled as such?
print("Precision:",metrics.precision_score(Y_test, y_pred_rbf,average='weighted'))
# Model Recall: what percentage of positive tuples are labelled as such?
print("Recall:",metrics.recall_score(Y_test, y_pred_rbf,average='weighted'))

#using poly kernel
clf_poly = svm.SVC(kernel='poly',degree=3,random_state=53) # poly Kernel
clf_poly.fit(X_train,Y_train)
#Predict the response for test dataset
y_pred_poly = clf_poly.predict(X_test)

# Model Accuracy: how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(Y_test, y_pred_poly))
# Model Precision: what percentage of positive tuples are labeled as such?
print("Precision:",metrics.precision_score(Y_test, y_pred_poly,average='weighted'))
# Model Recall: what percentage of positive tuples are labelled as such?
print("Recall:",metrics.recall_score(Y_test, y_pred_poly,average='weighted'))